* what is HAdoop
* what is a data lake
* what is a data swamp
* what is a data warehouse
* what is Hive
* what is meant by big data
* what is Yarn
* what is MapReduce
* what is batch processing
* what is pyspark
* what are the five Vs of big data
* what are the phases of MapReduce
* what is a node
* what is a reducer
* what is a data mart
* what is ELT
* what is ETL
* what is a data silo
* pros of data warehouse
* cons of data warehouse
* pros of data lake
* cons of data lakes
* what is meant by commodity hardware
* how do data lakes fit into the existing data architecture
* advantages of the MapReduce approach
* what are the core components of Hadoop
* what is Hdfs
* what is meant by master-worker architecture
* what is oozie
* what is spark
* what is flume
* what is mahhout
* what is zookeepr
* what is pig
* what is the purpose of a resource manager
* how do prevent a data lake from becoming a data swamp
* which pyspark method is used to load data from a file (rdd)
* what does rdd stand for
* how do you create an rdd from a list
* what is flatMap()  (rdd)
* what rdd pyspark method can be used to transform each entry 
* why can't print be used by itself
* what is clustered computing
* what is parallel computing 
* what is distributed computing
* what is real-time processing
* what is batch processing
* what are the main ways of ingesting data
* what do dataframes allow us to do that rdds cannot
* what is the purpose of a lambda in pyspark (rdd)
* what is the purpose of reduceByKey()
* * what does filter() do pyspark (rdd)
* what is the entry point to Spark
* what is the purpose of having an entry point in spark
* what represents the entry point to Spark functionality
* where does the SparkContext get initiated
* how might you find the number of times that each word in a file occurs
* how do we create RDDs
* why are RDDs called RDDs - what are their characteristics
* what is a cluster
* what is a node
* what are lambdas often used with
* What is SparkContext
* what is lazy evaluation in RDDs[]
* what is data virtualization
* differences between data migration and data integration
* what are some data cleansing techniques
* what is data partitioning
* what is a partition in Spark
* are RDDs immutable or mutable
* what does getNumPartitions() do
 * what are the two different types of operations in PySpark
* what might be a use case for using flatMap() method of pyspark (rdd)
* what is the difference between map() and flatMap() (rdd)
* what does union() do
* what is meant by lazy evaluation
* what are the four actions()
